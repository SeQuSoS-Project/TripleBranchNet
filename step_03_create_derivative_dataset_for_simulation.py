import os
import json
import numpy as np
import time
import glob
import warnings
import logging
from tqdm import tqdm
from qiskit import QuantumCircuit, transpile
from qiskit.quantum_info import DensityMatrix, state_fidelity
from qiskit_ibm_runtime.fake_provider import FakeBrisbane
from qiskit_aer import AerSimulator
from qiskit_aer.noise import NoiseModel, ReadoutError, pauli_error
from qiskit_aer.noise.errors import depolarizing_error, thermal_relaxation_error
from qiskit.transpiler import PassManager
from qiskit.transpiler.basepasses import TransformationPass
from qiskit.dagcircuit import DAGCircuit
from qiskit.circuit.library import RZZGate
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing
from typing import Optional # Enables 'Optional[type]' for type hints

# Suppress specific Qiskit Aer noise model warnings for cleaner console output.
warnings.filterwarnings("ignore")
logging.getLogger("qiskit_aer.noise.utils").setLevel(logging.ERROR)
np.random.seed(42) # Sets a seed for NumPy's random number generator for reproducibility.

# --- Configuration ---
# Defines the relative path to the input dataset, generated by 'test_train_creator.py'.
# Users must update the timestamped folder name to match their actual combined dataset.
COMBINED_DATASET_PATH_RELATIVE = os.path.join("combined_datasets", "combined_mixed_YYYYMMDD_HHMMSS") # <--- MANUAL UPDATE REQUIRED

# Defines the base directory for all generated processed (derivative) datasets.
PROCESSED_OUTPUT_BASE_DIR = "processed_datasets"

# Generates a unique timestamp for the current script execution.
CURRENT_RUN_TIMESTAMP = time.strftime("%Y%m%d_%H%M%S")

# Constructs the full path for the specific output directory for this run.
output_dir_name = f"dataset_{os.path.basename(COMBINED_DATASET_PATH_RELATIVE)}"
OUTPUT_DIR = os.path.join(PROCESSED_OUTPUT_BASE_DIR, output_dir_name)

# Defines specific sub-paths for storing density matrices, the JSON Lines file, and the processing log.
DM_OUTPUT_DIR = os.path.join(OUTPUT_DIR, "dm")
JSONL_FILE_PATH = os.path.join(OUTPUT_DIR, "dataset.jsonl")
LOG_FILE_PATH = os.path.join(OUTPUT_DIR, "dataset_creator_log.txt")

# Creates all necessary output directories if they do not already exist.
os.makedirs(DM_OUTPUT_DIR, exist_ok=True)

# Defines qubit triplets for ZZ crosstalk simulation, mapping active qubit pairs
# to their respective spectator qubits.
CROSSTALK_TRIPLETS = {
    (0, 1): [2], (1, 2): [0, 3], (2, 3): [1, 4], (3, 4): [2, 5],
    (4, 5): [3, 6], (5, 6): [4, 7], (6, 7): [5, 8], (7, 8): [6, 9], (8, 9): [7]
}

# Initializes lists to accumulate data for the JSONL file and log entries during processing.
jsonl_data = []
log_entries = []

# --- Utility Functions for Quantum Circuit Processing ---

def build_triplet_zz_angle_map(backend, zeta_mhz=1.2):
    """
    Calculates RZZ gate angles for crosstalk interactions based on backend properties
    (ECR gate durations) and a specified 'zeta' coupling strength.
    """
    angle_map = {}
    props = backend.properties()
    ecr_durations = {
        tuple(gate.qubits): next((p.value for p in gate.parameters if p.name == "gate_length"), None)
        for gate in props.gates if gate.gate == "ecr"
    }
    for (qA, qB), spectators in CROSSTALK_TRIPLETS.items():
        duration = ecr_durations.get((qA, qB)) or ecr_durations.get((qB, qA))
        if duration:
            theta = 2 * np.pi * zeta_mhz * 1e6 * duration
            for s in spectators:
                angle_map[(qA, s)] = theta
                angle_map[(qB, s)] = theta
    return angle_map

class ZZCrosstalkPass(TransformationPass):
    """
    A custom Qiskit transpiler pass that inserts RZZ gates to simulate ZZ crosstalk.
    RZZ gates are applied to specific qubit pairs with angles determined by `zz_angle_map`.
    """
    def __init__(self, zz_angle_map):
        super().__init__()
        self.zz_angle_map = zz_angle_map

    def run(self, dag: DAGCircuit) -> DAGCircuit:
        """
        Applies RZZ gates to the circuit's DAG, representing crosstalk interactions.
        """
        for (q0, q1), theta in self.zz_angle_map.items():
            dag.apply_operation_back(RZZGate(theta), [dag.qubits[q0], dag.qubits[q1]])
        return dag

def insert_id_gates(qc: QuantumCircuit, qubits: list):
    """
    Inserts identity (idle) gates on specified qubits within a quantum circuit.
    """
    for q in qubits:
        qc.id(q)

def trace_distance(rho1: DensityMatrix, rho2: DensityMatrix) -> float:
    """
    Calculates the trace distance between two quantum density matrices,
    quantifying the distinguishability between the states.
    """
    diff = rho1.data - rho2.data
    eigvals = np.linalg.eigvalsh(diff @ diff.conj().T)
    return 0.5 * np.sum(np.sqrt(np.clip(eigvals, 0, None)))

def build_noise_model(add_decoherence: bool = False, add_readout: bool = False, add_stochastic_pauli: bool = False, circuit: Optional[QuantumCircuit] = None) -> NoiseModel:
    """
    Constructs a Qiskit Aer NoiseModel based on `FakeBrisbane` properties.
    Configurable parameters include decoherence, readout errors, and stochastic Pauli crosstalk errors.
    """
    backend = FakeBrisbane()
    properties = backend.properties()
    config = backend.configuration()
    noise_model = NoiseModel()

    t1_t2_map = {i: (q[0].value * 1e3, q[1].value * 1e3) for i, q in enumerate(properties.qubits)}

    if add_readout:
        for qubit in range(len(properties.qubits)):
            try:
                err = properties.readout_error(qubit)
                if isinstance(err, float) and err > 0:
                    ro = ReadoutError([[1 - err, err], [err, 1 - err]])
                    noise_model.add_readout_error(ro, [qubit])
            except Exception:
                continue

    for gate in properties.gates:
        name, qubits = gate.gate, gate.qubits
        try: gate_length = config.gate_length(name, qubits) * 1e9
        except Exception: gate_length = 100

        try:
            err = next(p for p in gate.parameters if p.name == "gate_error")
            if name in ["x", "sx", "rz", "id"]:
                q = qubits[0]
                composed = depolarizing_error(err.value, 1)
                if add_decoherence:
                    t1, t2 = t1_t2_map[q]
                    relax = thermal_relaxation_error(t1, min(t2, 2*t1), gate_length, 1)
                    composed = relax.compose(composed)
                noise_model.add_quantum_error(composed, name, [q])
            elif name == "ecr":
                q0, q1 = qubits
                composed = depolarizing_error(err.value, 2)
                if add_decoherence:
                    t1a, t2a = t1_t2_map[q0]
                    t1b, t2b = t1_t2_map[q1]
                    relax = thermal_relaxation_error(t1a, min(t2a, 2*t1a), gate_length, 1).expand(
                        thermal_relaxation_error(t1b, min(t2b, 2*t1b), gate_length, 1))
                    composed = relax.compose(composed)
                noise_model.add_quantum_error(composed, name, [q0, q1])
        except StopIteration:
            continue
        except Exception:
            continue

    if add_stochastic_pauli and circuit is not None:
        p_ct = 0.01
        used_pairs = set()
        for inst, qargs, _ in circuit.data:
            if inst.name in ["cx", "ecr"] and len(qargs) == 2:
                q0, q1 = qargs[0]._index, qargs[1]._index
                used_pairs.add((q0, q1))
                used_pairs.add((q1, q0))
        spectator_error_map = {}
        for (q0, q1), spectators in CROSSTALK_TRIPLETS.items():
            if (q0, q1) in used_pairs:
                for s in spectators:
                    xz = pauli_error([("X", p_ct/2), ("Z", p_ct/2), ("I", 1 - p_ct)])
                    if s in spectator_error_map:
                        spectator_error_map[s] = spectator_error_map[s].compose(xz)
                    else:
                        spectator_error_map[s] = xz
        for q, err in spectator_error_map.items():
            noise_model.add_quantum_error(err, "id", [q])

    return noise_model

def simulate_density_matrix(qc: QuantumCircuit, noise_model: Optional[NoiseModel] = None) -> DensityMatrix:
    """
    Simulates a quantum circuit to obtain its density matrix, optionally applying a noise model.
    """
    sim = AerSimulator(noise_model=noise_model, seed_simulator=42)
    qc.save_density_matrix()
    transpiled = transpile(qc, backend=sim, optimization_level=0)
    result = sim.run(transpiled).result()
    return DensityMatrix(result.data(0)['density_matrix'])

def extract_circuit_features(qc: QuantumCircuit) -> dict:
    """
    Extracts structural and operational features from a quantum circuit,
    including depth, number of qubits, gate counts, and initial X-qubits.
    """
    gate_counts = qc.count_ops()
    init_x = [q._index for q in qc.qubits if any(instr[0].name == 'x' and instr[1][0] == q for instr in qc.data[:len(qc.qubits)])]
    return {
        "depth": qc.depth(),
        "num_qubits": len(qc.qubits),
        "gate_counts": dict(gate_counts),
        "init_x_qubits": init_x
    }

def process_one_file(qasm_file: str, timestamp: str) -> Optional[dict]:
    """
    Processes a single QASM file: loads circuit and ideal state, simulates under
    different noise scenarios, calculates fidelities and trace distances,
    and prepares data for JSONL output and logging.
    """
    try:
        filename = os.path.basename(qasm_file)
        file_id = f"{filename}_{timestamp}"

        # Construct paths to the corresponding state, label, and fidelity files.
        # These paths are relative to the combined dataset's root.
        state_path = os.path.join(COMBINED_DATASET_PATH_RELATIVE, "state", filename)
        label_path = os.path.join(COMBINED_DATASET_PATH_RELATIVE, "label", filename)
        fidelity_path = os.path.join(COMBINED_DATASET_PATH_RELATIVE, "fidelity", filename)

        qc = QuantumCircuit.from_qasm_file(qasm_file)

        state_raw = np.loadtxt(state_path)
        ideal_state = state_raw[:, 0] + 1j * state_raw[:, 1]
        ideal_dm = DensityMatrix(ideal_state)

        with open(fidelity_path, "r") as f:
            f_groundtruth = float(f.read().strip())
        with open(label_path, "r") as f:
            mnist_label = int(f.read().strip())

        circuit_features = extract_circuit_features(qc)

        # --- Case 2: Ideal Simulation ---
        dm_case2 = simulate_density_matrix(qc.copy(), None)
        fidelity_case2 = state_fidelity(ideal_dm, dm_case2)

        # --- Case 3: Decoherence and Readout Noise ---
        qc3 = qc.copy()
        insert_id_gates(qc3, list(range(10)))
        noise_model_case3 = build_noise_model(add_decoherence=True, add_readout=True, circuit=qc3)
        dm_case3 = simulate_density_matrix(qc3, noise_model_case3)
        fidelity_case3 = state_fidelity(ideal_dm, dm_case3)

        # --- Case 7: Combined Noise (Decoherence + Readout + ZZ Crosstalk + Stochastic Pauli Crosstalk) ---
        qc7 = qc.copy()
        zz_map = build_triplet_zz_angle_map(FakeBrisbane())
        qc7 = PassManager([ZZCrosstalkPass(zz_map)]).run(qc7)
        insert_id_gates(qc7, list(range(10)))
        noise_model_case7 = build_noise_model(add_decoherence=True, add_readout=True, add_stochastic_pauli=True, circuit=qc7)
        dm_case7 = simulate_density_matrix(qc7, noise_model_case7)
        fidelity_case7 = state_fidelity(ideal_dm, dm_case7)

        trace_case3 = trace_distance(ideal_dm, dm_case3)
        trace_case7 = trace_distance(ideal_dm, dm_case7)
        delta_trace = trace_case7 - trace_case3

        dm_real = dm_case7.data.real
        dm_imag = dm_case7.data.imag
        mask = np.triu(np.ones(dm_real.shape, dtype=bool))
        vec_real = dm_real[mask]
        vec_imag = dm_imag[mask]
        dm7_vec = np.concatenate([vec_real, vec_imag]).astype(np.float32)

        dm_filename = f"case7_{file_id}.npz"
        dm_path_out = os.path.join(DM_OUTPUT_DIR, dm_filename)
        np.savez_compressed(dm_path_out, dm=dm7_vec)

        log_info = f"{filename},{timestamp}"

        return {
            "jsonl": {
                "filename": filename,
                "mnist_label": mnist_label,
                "input": {
                    "density_matrix_path": os.path.relpath(dm_path_out, OUTPUT_DIR),
                    "circuit_features": circuit_features
                },
                "metrics": {
                    "fidelity_ideal_simulation": round(fidelity_case2, 6),
                    "fidelity_decoherence_readout": round(fidelity_case3, 6),
                    "fidelity_combined_noise": round(fidelity_case7, 6),
                    "trace_distance_decoherence_readout": round(trace_case3, 6),
                    "trace_distance_combined_noise": round(trace_case7, 6)
                },
                "target": {
                    "delta_trace": round(delta_trace, 6)
                }
            },
            "log": log_info
        }
    except Exception as e:
        print(f"\u274c Error processing {qasm_file}: {e}")
        return None

# --- Main Execution Block ---
if __name__ == "__main__":
    multiprocessing.freeze_support()

    qasm_files = glob.glob(os.path.join(COMBINED_DATASET_PATH_RELATIVE, "qasm", "*"))
    print(f"Discovered {len(qasm_files)} QASM files for processing.")
    print(f"Output data will be generated in: {OUTPUT_DIR}")

    with ProcessPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(process_one_file, file, CURRENT_RUN_TIMESTAMP) for file in qasm_files]

        for f in tqdm(as_completed(futures), total=len(futures), desc="Processing Files"):
            res = f.result()
            if res:
                jsonl_data.append(res["jsonl"])
                log_entries.append(res["log"])

    with open(JSONL_FILE_PATH, "w") as f:
        for entry in jsonl_data:
            f.write(json.dumps(entry) + "\n")

    with open(LOG_FILE_PATH, "w") as f:
        for line in log_entries:
            f.write(line + "\n")

    print(f"\n✅ Dataset creation complete. Processed {len(jsonl_data)} files.")
    print(f"JSONL data saved to: {JSONL_FILE_PATH}")
    print(f"Log file saved to: {LOG_FILE_PATH}")
    print(f"Density matrices saved to: {DM_OUTPUT_DIR}")